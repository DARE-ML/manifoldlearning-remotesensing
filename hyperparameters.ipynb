{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-optimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import umap\n",
    "\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from sklearn import cluster\n",
    "from sklearn.manifold import TSNE, Isomap, SpectralEmbedding, LocallyLinearEmbedding\n",
    "from sklearn.metrics import v_measure_score\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "data_array = loadmat('./Indian_pines_corrected.mat')['indian_pines_corrected'] # Hyperspectral data\n",
    "gt = loadmat('./Indian_pines_gt.mat')['indian_pines_gt'] # Ground truth data\n",
    "\n",
    "data_reshaped = data_array.reshape(data_array.shape[0]*data_array.shape[1], -1)\n",
    "data_reshaped = minmax_scale(data_reshaped, feature_range=(0, 1), axis=0, copy=False)\n",
    "gt_reshaped = gt.flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = TSNE(random_state=1,n_components=2)\n",
    "# The hyperparameter space which we would be using to search\n",
    "search_space = [Integer(10, 50, name='perplexity'),Integer(250, 1000, name='n_iter')]\n",
    "clusterer = cluster.KMeans(n_clusters=17, random_state=1) # create an object of the classifier\n",
    "\n",
    "# The function which would be used to evaluate the given configuration\n",
    "@use_named_args(search_space)\n",
    "def evaluate_model(**params):\n",
    "\t#Setting the parameters of the model\n",
    "\tmodel.set_params(**params)\n",
    "\t# calculate 5-fold cross validation\n",
    "\tselected_components_tsne = model.fit_transform(data_reshaped)\n",
    "\tlabels = clusterer.fit_predict(selected_components_tsne)\n",
    "\tresult= v_measure_score(gt_reshaped, labels)\n",
    "\treturn 1-result\n",
    "\n",
    "\n",
    "# perform optimization\n",
    "result = gp_minimize(evaluate_model, search_space,n_jobs=-1,n_calls=100)\n",
    "# summarizing finding:\n",
    "print('Best Accuracy: %.3f' % (1.0 - result.fun))\n",
    "print('Best Parameters: perplexity=%d, n_iter=%d' % (result.x[0], result.x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Isomap(n_components=2)\n",
    "# The hyperparameter space which we would be using to search\n",
    "search_space = [Integer(1, 100, name='n_neighbors')]\n",
    "clusterer = cluster.KMeans(n_clusters=17, random_state=1) # create an object of the classifier\n",
    "count=0\n",
    "# The function which would be used to evaluate the given configuration\n",
    "@use_named_args(search_space)\n",
    "def evaluate_model(**params):\n",
    "\tglobal count\n",
    "\tcount+=1\n",
    "\t#Setting the parameters of the model\n",
    "\tmodel.set_params(**params)\n",
    "\t# calculate 5-fold cross validation\n",
    "\tselected_components_isomap = model.fit_transform(data_reshaped)\n",
    "\tlabels = clusterer.fit_predict(selected_components_isomap)\n",
    "\tresult= v_measure_score(gt_reshaped, labels)\n",
    "\tprint(count,\"percent done\",result)\n",
    "\treturn 1-result\n",
    "\n",
    "# perform optimization\n",
    "result = gp_minimize(evaluate_model, search_space,n_jobs=-1,n_calls=100)\n",
    "# summarizing finding:\n",
    "print('Best Accuracy: %.3f' % (1.0 - result.fun))\n",
    "print('Best Parameters: n_neighbours=%d' % (result.x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpectralEmbedding(n_jobs=-1,affinity='nearest_neighbors',n_components=2,random_state=1)\n",
    "# The hyperparameter space which we would be using to search\n",
    "search_space = [Integer(1, 100, name='n_neighbors')]\n",
    "clusterer = cluster.KMeans(n_clusters=17, random_state=1) # create an object of the classifier\n",
    "count=0\n",
    "# The function which would be used to evaluate the given configuration\n",
    "@use_named_args(search_space)\n",
    "def evaluate_model(**params):\n",
    "\tglobal count\n",
    "\tcount+=1\n",
    "\t#Setting the parameters of the model\n",
    "\tmodel.set_params(**params)\n",
    "\t# calculate 5-fold cross validation\n",
    "\tselected_components_spec_embed = model.fit_transform(data_reshaped)\n",
    "\tlabels = clusterer.fit_predict(selected_components_spec_embed)\n",
    "\tresult= v_measure_score(gt_reshaped, labels)\n",
    "\tprint(count,\"percent done\",result)\n",
    "\treturn 1-result\n",
    "\n",
    "# perform optimization\n",
    "result = gp_minimize(evaluate_model, search_space,n_jobs=-1,n_calls=100)\n",
    "# summarizing finding:\n",
    "print('Best Accuracy: %.3f' % (1.0 - result.fun))\n",
    "print('Best Parameters: n_neighbours=%d' % (result.x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LocallyLinearEmbedding(method='modified', n_jobs=-1, random_state=1,n_components=2)                                                        \n",
    "# The hyperparameter space which we would be using to search\n",
    "search_space = [Integer(2, 20, name='n_neighbors'),Real(0.0001, 0.01, name='reg'),Integer(50,200, name='max_iter')]\n",
    "clusterer = cluster.KMeans(n_clusters=17, random_state=1) # create an object of the classifier\n",
    "count=0\n",
    "# The function which would be used to evaluate the given configuration\n",
    "@use_named_args(search_space)\n",
    "def evaluate_model(**params):\n",
    "    global count\n",
    "    count+=1\n",
    "    try:\n",
    "        model.set_params(**params)\n",
    "        # calculate 5-fold cross validation\n",
    "        selected_components_tsne = model.fit_transform(data_reshaped)\n",
    "        # print(\"Got selected compoonents\")\n",
    "        labels = clusterer.fit_predict(selected_components_tsne) # train\n",
    "        # print(\"Got labels\")\n",
    "        result= v_measure_score(gt_reshaped, labels)\n",
    "        print(count,\"percent done\",result)\n",
    "        return 1-result\n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "\n",
    "# perform optimization\n",
    "result = gp_minimize(evaluate_model, search_space,n_jobs=-1,n_calls=100)\n",
    "# summarizing finding:\n",
    "print('Best Accuracy: %.3f' % (1.0 - result.fun))\n",
    "print('Best Parameters: n_neighbours=%d,reg={}, max_iter=%d ' %  (result.x[0], result.x[1],result.x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=[ 'euclidean' ,'manhattan' , 'chebyshev' , 'minkowski' , 'canberra' , 'braycurtis' , 'mahalanobis' , 'wminkowski']\n",
    "model = umap.UMAP(n_jobs=-1,random_state=1,n_components=2)\n",
    "# The hyperparameter space which we would be using to search\n",
    "search_space = [Integer(3, 20, name='n_neighbors'),Real(0.001, 0.5, name='min_dist'),Real(0.5, 3, name='spread'),Categorical(cat,name='metric')]\n",
    "clusterer = cluster.KMeans(n_clusters=17, random_state=1) # create an object of the classifier\n",
    "count=0\n",
    "# The function which would be used to evaluate the given configuration\n",
    "@use_named_args(search_space)\n",
    "def evaluate_model(**params):\n",
    "\tglobal count\n",
    "\tcount+=1\n",
    "\ttry:\n",
    "\t\t#Setting the parameters of the model\n",
    "\t\tmodel.set_params(**params)\n",
    "\t\t# calculate 5-fold cross validation\n",
    "\t\tselected_components_tsne = model.fit_transform(data_reshaped)\n",
    "\t\t# print(\"Got selected compoonents\")\n",
    "\t\tlabels = clusterer.fit_predict(selected_components_tsne) # train\n",
    "\t\t# print(\"Got labels\")\n",
    "\t\tresult= v_measure_score(gt_reshaped, labels)\n",
    "\t\tprint(count,\"percent done\",result)\n",
    "\t\treturn 1-result\n",
    "\texcept:\n",
    "\t\treturn 1\n",
    "\n",
    "# perform optimization\n",
    "result = gp_minimize(evaluate_model, search_space,n_jobs=-1,n_calls=100)\n",
    "# summarizing finding:\n",
    "print('Best Accuracy: %.3f' % (1.0 - result.fun))\n",
    "print('Best Parameters: n_neighbours=%d,min_dist=%d, spread=%d, metric=%d ' %  (result.x[0], result.x[1],result.x[2], result.x[3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53d4c9413b273a4c2feb371c3b80ba916c0b6b454358383ea94d1e46168b95dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
